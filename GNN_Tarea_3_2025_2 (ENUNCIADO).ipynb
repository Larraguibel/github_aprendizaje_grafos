{"cells":[{"cell_type":"markdown","metadata":{"id":"FyoSWRNG4V6j"},"source":["Pontificia Universidad Católica de Chile <br>\n","Departamento de Ciencia de la Computación <br>\n","IIC3641 - Aprendizaje Automático Basado en Grafos <br>\n","Segundo Semestre 2025<br>\n","\n","\n","<h1><center> Tarea 3  </center></h1>\n","        Profesor: Marcelo Mendoza<br>\n","        Fecha de entrega: 22 de octubre\n","\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"IqaM5wrU4V6o"},"source":["## Indicaciones\n","\n","Se debe entregar **SOLO** el archivo .ipynb en el buzón respectivo en canvas.\n","\n","**IMPORTANTE**:\n","- Se asignará puntaje por el código implementado y los comentarios asociados a resultados.\n","- El notebook debe tener todas las celdas de código ejecutadas.\n","- Cualquier instancia de copia resultará en un 1.1 como nota de curso.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"T6riRFCN49it"},"source":["# Integrantes del grupo\n","\n","* Estudiante 1: Juan Hernandez\n","* Estudiante 2: Ignacio Vergara\n","* Estudiante 3: Diego Larraguibel"]},{"cell_type":"markdown","metadata":{"id":"qF99zSnD4V6o"},"source":["# Librerías"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"p1EkKCy15B_W"},"outputs":[],"source":["import dgl\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","import networkx as nx\n","import torch\n","\n","device = \"mps\""]},{"cell_type":"markdown","metadata":{"id":"Tp5iLrOZFTg8"},"source":["# Parte 1: Relational Graph Convolutional Network (R-GCN) (20 puntos)"]},{"cell_type":"markdown","metadata":{"id":"qSvYsD0nignx"},"source":["En esta primera sección se trabaja con el dataset BGSDataset, disponible en dgl.\n","\n","Ver enlace: https://www.dgl.ai/dgl_docs/generated/dgl.data.BGSDataset.html#dgl.data.BGSDataset\n","\n","**Observación**\n","\n","Para trabajar con el código visto en clases deben ajustar la versión de pytorch."]},{"cell_type":"markdown","metadata":{"id":"uwbHoCEgFds8"},"source":["## 1.1 Conceptos básicos (5 puntos)\n"]},{"cell_type":"markdown","metadata":{"id":"d3GdiYd9R2jU"},"source":["Responda las siguientes preguntas:\n","\n","1. Mencione y describa los elementos que diferencian las arquitecturas **GCN** y **R-GCN**.\n","\n","2. Explique las principales diferencias en el proceso de entrenamiento de arquitecturas basadas en **R-GCN**, considerando las tareas **Clasificación de nodos** y **Predicción de enlaces**"]},{"cell_type":"markdown","metadata":{"id":"JjUWKBQwRe8n"},"source":["Respuesta:"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{"id":"mzYbN_j6ub7m"},"source":["## 1.2 Análisis descriptivo (5 puntos)"]},{"cell_type":"markdown","metadata":{"id":"EA7YLoynv3s6"},"source":["Grafique el grafo y calcule medidas descriptivas para caracterizarlo. Comente sus resultados.\n","\n","**Observación**\n","\n","En caso de no poder graficar la red completa, se recomienda trabajar con un subconjunto de 15.000 nodos (demora cerca de 12 minutos). Esto **SOLO** aplica para este punto. **La actividad 1.3 debe considerar todo el grafo.**"]},{"cell_type":"markdown","metadata":{"id":"n3xI-QkdufPl"},"source":["Respuesta:"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"9gKAaHpgwS6U"},"outputs":[{"name":"stdout","output_type":"stream","text":["Done loading data from cached files.\n"]}],"source":["ds = dgl.data.BGSDataset()\n","g = ds[0]\n","category = ds.predict_category\n","num_classes = ds.num_classes\n","train_mask = g.nodes[category].data['train_mask']\n","test_mask = g.nodes[category].data['test_mask']\n","label = g.nodes[category].data['label']"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m largest_cc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(nx\u001b[38;5;241m.\u001b[39mconnected_components(G_undirected), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m)\n\u001b[1;32m      4\u001b[0m G_largest \u001b[38;5;241m=\u001b[39m G_undirected\u001b[38;5;241m.\u001b[39msubgraph(largest_cc)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 5\u001b[0m pos_data \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspring_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG_largest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      7\u001b[0m nx\u001b[38;5;241m.\u001b[39mdraw(\n\u001b[1;32m      8\u001b[0m     G_largest, pos_data,\n\u001b[1;32m      9\u001b[0m     node_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     with_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m )\n","File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 4:4\u001b[0m, in \u001b[0;36margmap_spring_layout_1\u001b[0;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n","File \u001b[0;32m~/miniforge3/envs/dgl-arm/lib/python3.10/site-packages/networkx/drawing/layout.py:486\u001b[0m, in \u001b[0;36mspring_layout\u001b[0;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[1;32m    484\u001b[0m         nnodes, _ \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    485\u001b[0m         k \u001b[38;5;241m=\u001b[39m dom_size \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(nnodes)\n\u001b[0;32m--> 486\u001b[0m     pos \u001b[38;5;241m=\u001b[39m \u001b[43m_sparse_fruchterman_reingold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m     A \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mto_numpy_array(G, weight\u001b[38;5;241m=\u001b[39mweight)\n","File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 12:4\u001b[0m, in \u001b[0;36margmap__sparse_fruchterman_reingold_9\u001b[0;34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n","File \u001b[0;32m~/miniforge3/envs/dgl-arm/lib/python3.10/site-packages/networkx/drawing/layout.py:621\u001b[0m, in \u001b[0;36m_sparse_fruchterman_reingold\u001b[0;34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[0m\n\u001b[1;32m    619\u001b[0m delta \u001b[38;5;241m=\u001b[39m (pos[i] \u001b[38;5;241m-\u001b[39m pos)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    620\u001b[0m \u001b[38;5;66;03m# distance between points\u001b[39;00m\n\u001b[0;32m--> 621\u001b[0m distance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;66;03m# enforce minimum distance of 0.01\u001b[39;00m\n\u001b[1;32m    623\u001b[0m distance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(distance \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, distance)\n","File \u001b[0;32m~/miniforge3/envs/dgl-arm/lib/python3.10/site-packages/numpy/core/_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["G = dgl.to_networkx(g)\n","G_undirected = G.to_undirected()\n","largest_cc = max(nx.connected_components(G_undirected), key=len)\n","G_largest = G_undirected.subgraph(largest_cc).copy()\n","pos_data = nx.spring_layout(G_largest, seed=1001)\n","plt.figure(figsize=(8, 8))\n","nx.draw(\n","    G_largest, pos_data,\n","    node_size=10,\n","    node_color='skyblue',\n","    edge_color='gray',\n","    with_labels=False,\n",")\n","plt.title(\"Mayor componente conexa del grafo\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def funcion_descriptora(G, nombre):\n","    # Printeo de las características solicitadas\n","    df_datos = pd.DataFrame([{\"Nodos\": None, \"Aristas\": None, \"Componentes\": None, \"Grado Promedio\": None, \"Diámetro\": None, \"Camino mínimo promedio\": None}])\n","    df_datos[\"Nodos\"] = len(G.nodes())\n","    df_datos[\"Aristas\"] = len(G.edges())\n","    df_datos[\"Componentes\"] = nx.number_connected_components(G)\n","    degrees = np.array([G.degree(n) for n in G.nodes()])\n","    df_datos[\"Grado Promedio\"] = np.mean(degrees)\n","    # En caso de que el grafo no sea conexo se debe determinar el diámetro analizando cada subgrafo del mismo\n","    if nx.is_connected(G):\n","        df_datos[\"Diámetro\"] = nx.diameter(G)\n","    else:\n","        diam = 0\n","        for component in nx.connected_components(G):\n","            subgraph = G.subgraph(component)\n","            d = nx.diameter(subgraph)\n","            if diam <= d:\n","                diam = d\n","        df_datos[\"Diámetro\"] = diam\n","\n","    componentes = list(nx.connected_components(G))\n","    nodos_mayor_comp = max(componentes, key=len)\n","    mayor_comp = G.subgraph(nodos_mayor_comp)\n","    cmp_mayor_comp = nx.average_shortest_path_length(mayor_comp) # Camino mínimo promedio de la mayor componente\n","    df_datos[\"Camino mínimo promedio\"] = cmp_mayor_comp\n","\n","    print(f\"Las estadísticas del grafo {nombre} son:\")\n","    display(df_datos)\n","\n","funcion_descriptora(G, \"BGS\")"]},{"cell_type":"markdown","metadata":{},"source":["### Comentario sobre el grafo"]},{"cell_type":"markdown","metadata":{"id":"JD3E6k_8VACq"},"source":["## 1.3 Implementación R-GCN (10 puntos)"]},{"cell_type":"markdown","metadata":{"id":"ifkLDO0HR6XV"},"source":["Entrene una arquitectura R-GCN para clasificar entidades. Defina el número de épocas de manera que se garantice la convergencia del entrenamiento y justifique su elección de hiperpámetros.\n","\n","Grafique la función de pérdida y accuracy. Comente sus resultados."]},{"cell_type":"markdown","metadata":{"id":"xZ747f0dfmmS"},"source":["Respuesta:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Copiamos las clases para construir R-GCN desde la clase 10.\n","from functools import partial\n","\n","import dgl\n","import dgl.function as fn\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from dgl import DGLGraph\n","\n","\n","class RGCNLayer(nn.Module):\n","    def __init__(\n","        self,\n","        in_feat,\n","        out_feat,\n","        num_rels,\n","        num_bases=-1, # esto indica que num_bases = num_rels\n","        bias=None,\n","        activation=None,\n","        is_input_layer=False,\n","    ):\n","        super(RGCNLayer, self).__init__()\n","        self.in_feat = in_feat\n","        self.out_feat = out_feat\n","        self.num_rels = num_rels\n","        self.num_bases = num_bases # implementación eficiente de relaciones con combinación lineal de matrices base.\n","        self.bias = bias\n","        self.activation = activation\n","        self.is_input_layer = is_input_layer\n","\n","        \n","        if self.num_bases <= 0 or self.num_bases > self.num_rels:\n","            self.num_bases = self.num_rels\n","        \n","        self.weight = nn.Parameter(\n","            torch.Tensor(self.num_bases, self.in_feat, self.out_feat)\n","        )\n","        if self.num_bases < self.num_rels:\n","            \n","            self.w_comp = nn.Parameter(\n","                torch.Tensor(self.num_rels, self.num_bases)\n","            )\n","        # add bias\n","        if self.bias:\n","            self.bias = nn.Parameter(torch.Tensor(out_feat))\n","        # init trainable parameters\n","        nn.init.xavier_uniform_(\n","            self.weight, gain=nn.init.calculate_gain(\"relu\")\n","        )\n","        if self.num_bases < self.num_rels:\n","            nn.init.xavier_uniform_(\n","                self.w_comp, gain=nn.init.calculate_gain(\"relu\")\n","            )\n","        if self.bias:\n","            nn.init.xavier_uniform_(\n","                self.bias, gain=nn.init.calculate_gain(\"relu\")\n","            )\n","\n","    def forward(self, g):\n","        if self.num_bases < self.num_rels:\n","            weight = self.weight.view(\n","                self.in_feat, self.num_bases, self.out_feat\n","            )\n","            weight = torch.matmul(self.w_comp, weight).view(\n","                self.num_rels, self.in_feat, self.out_feat\n","            )\n","        else:\n","            weight = self.weight\n","        if self.is_input_layer:\n","\n","            def message_func(edges):\n","                embed = weight.view(-1, self.out_feat)\n","                index = edges.data[dgl.ETYPE] * self.in_feat + edges.src[\"id\"]\n","                return {\"msg\": embed[index] * edges.data[\"norm\"]}\n","\n","        else:\n","\n","            def message_func(edges):\n","                w = weight[edges.data[dgl.ETYPE]]\n","                msg = torch.bmm(edges.src[\"h\"].unsqueeze(1), w).squeeze()\n","                msg = msg * edges.data[\"norm\"]\n","                return {\"msg\": msg}\n","\n","        def apply_func(nodes):\n","            h = nodes.data[\"h\"]\n","            if self.bias:\n","                h = h + self.bias\n","            if self.activation:\n","                h = self.activation(h)\n","            return {\"h\": h}\n","\n","        g.update_all(message_func, fn.sum(msg=\"msg\", out=\"h\"), apply_func)\n","        \n","\n","class Model(nn.Module):\n","    def __init__(\n","        self,\n","        num_nodes,\n","        h_dim,\n","        out_dim,\n","        num_rels,\n","        num_bases=-1,\n","        num_hidden_layers=1,\n","    ):\n","        super(Model, self).__init__()\n","        self.num_nodes = num_nodes\n","        self.h_dim = h_dim\n","        self.out_dim = out_dim\n","        self.num_rels = num_rels\n","        self.num_bases = num_bases\n","        self.num_hidden_layers = num_hidden_layers\n","\n","        # create rgcn layers\n","        self.build_model()\n","\n","        # create initial features\n","        self.features = self.create_features()\n","\n","    def build_model(self):\n","        self.layers = nn.ModuleList()\n","        # input to hidden\n","        i2h = self.build_input_layer()\n","        self.layers.append(i2h)\n","        # hidden to hidden\n","        for _ in range(self.num_hidden_layers):\n","            h2h = self.build_hidden_layer()\n","            self.layers.append(h2h)\n","        # hidden to output\n","        h2o = self.build_output_layer()\n","        self.layers.append(h2o)\n","\n","    # initialize feature for each node\n","    def create_features(self):\n","        features = torch.arange(self.num_nodes)\n","        return features\n","\n","    def build_input_layer(self):\n","        return RGCNLayer(\n","            self.num_nodes,\n","            self.h_dim,\n","            self.num_rels,\n","            self.num_bases,\n","            activation=F.relu,\n","            is_input_layer=True,\n","        )\n","\n","    def build_hidden_layer(self):\n","        return RGCNLayer(\n","            self.h_dim,\n","            self.h_dim,\n","            self.num_rels,\n","            self.num_bases,\n","            activation=F.relu,\n","        )\n","\n","    def build_output_layer(self):\n","        return RGCNLayer(\n","            self.h_dim,\n","            self.out_dim,\n","            self.num_rels,\n","            self.num_bases,\n","            activation=partial(F.softmax, dim=1),\n","        )\n","\n","    def forward(self, g):\n","        if self.features is not None:\n","            g.ndata[\"id\"] = self.features\n","        for layer in self.layers:\n","            layer(g)\n","        return g.ndata.pop(\"h\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zsi2L1s-wYWi"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["**Observación**\n","\n","Para la pregunta 2 se recomienda revisar la publicación **Modeling\n","relational data with graph convolutional networks** (Schlichtkrull et al., 2018). Disponible en: https://arxiv.org/abs/1703.06103"]},{"cell_type":"markdown","metadata":{"id":"yaCSoRmET-HO"},"source":["# Parte 2: Graph Transformer (20 puntos)"]},{"cell_type":"markdown","metadata":{"id":"OkfWj0yLu4ns"},"source":["En esta segunda sección se debe trabajar con el conjunto de datos **caco2_wang**, contenido en el benchmark de ADMET.\n","\n","**Observación**\n","\n","Para cargar el dataset debe seguir el procedimiento visto en clases (8 - Graph-transformer)"]},{"cell_type":"markdown","metadata":{"id":"-pyNUnx1Hp_z"},"source":["## 2.1 Conceptos básicos (5 puntos)"]},{"cell_type":"markdown","metadata":{"id":"xcSPk_97H5sX"},"source":["Responda las siguientes preguntas:\n","\n","1. En el contexto de Graph Transformers, defina el concepto de **sparseness**. ¿Qué implicancias tiene este concepto en las capacidades de cómputo requeridas para trabajar con dichas arquitecturas?\n","\n","2. Explique el concepto de **positional encoding** en el contexto de los Graph Transformers y compare su formulación con la empleada en el Transformer original (Vaswani et al., 2017).\n","\n","**Observación**\n","\n","Se recomienda revisar la publicación **Attention Is All You Need** (Vaswani et al., 2017). Disponible en: https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf"]},{"cell_type":"markdown","metadata":{"id":"6l5LjiPRHtJ9"},"source":["Respuesta:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g5gWZ4gwH45q"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"L1sbdNxeIADa"},"source":["## 2.2 Implementación Graph Transformer (15 puntos)"]},{"cell_type":"markdown","metadata":{"id":"uv7mCGmNIIJi"},"source":["Proponga cuatro modelos para la tarea de regresión asociada al dataset **caco2_wang**, utilizando la arquitectura **Graph Transformer**. Para ello, haga modificaciones tanto en el número de cabezales como en el número de capas. Justifique sus decisiones.\n","\n","Compare sus resultados con el Leaderboard disponible en: https://tdcommons.ai/benchmark/admet_group/01caco2/\n","\n","**Observación**\n","\n","* Defina el número de épocas de manera que se garantice la convergencia del entrenamiento.\n","* Trabaje con los conjuntos ya definidos de train, val y test."]},{"cell_type":"markdown","metadata":{"id":"EUPHQ9TRIJco"},"source":["Respuesta:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0pq_gjh0IKkR"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"xKE2w1N6XDRn"},"source":["# Parte 3: Graphormer (20 puntos)"]},{"cell_type":"markdown","metadata":{"id":"aG8L6NXSXN6j"},"source":["En esta tercera sección se debe trabajar con el dataset **PubMed**.\n","\n","Este conjunto de datos está disponibles en pytorch-geometric. Ver enlace: https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.Planetoid.html#torch_geometric.datasets.Planetoid"]},{"cell_type":"markdown","metadata":{"id":"7mi5UIoOmPd4"},"source":["A continuación, se presenta el código para cargar el dataset."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"A_W2oO9NmQUj"},"outputs":[],"source":["from torch_geometric.datasets import Planetoid"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Ad2fMItzmRER"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n","Processing...\n","Done!\n"]}],"source":["dataset = Planetoid('./data/PubMed', 'PubMed') #definir root y el dataset que desea descargar\n","data = dataset[0]"]},{"cell_type":"markdown","metadata":{"id":"eO6GaS3UXOrm"},"source":["## 3.1 Conceptos básicos (5 puntos)"]},{"cell_type":"markdown","metadata":{"id":"yp8bVK_EXbtP"},"source":["Responda las siguientes preguntas:\n","1. ¿Que limitaciones del **Graph Attention Network** (GAT) intenta superar el Graphormer?\n","2. Describa las principales diferencias entre **Graphormer** y el **Graph Transformer original**.\n","3. Explique el concepto de **pooling** en el contexto de grafos. ¿En qué se diferencian **DiffPool** de **MinCutPool**?"]},{"cell_type":"markdown","metadata":{"id":"XvWLfATEXcf5"},"source":["Respuesta:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8LnjEpGMXdI0"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"XLf7aK7lXRjM"},"source":["## 3.2 DiffPool (5 puntos)"]},{"cell_type":"markdown","metadata":{"id":"PhZ5XknwXUS1"},"source":["En esta sección se entrenará un modelo Graphormer utilizando el método de pooling jerárquico DiffPool. Para ello, siga los siguientes pasos:\n","1. Entrene un Graphormer con pooling jerárquico `DiffPool` con 300 épocas.\n","2. Por cada 20 épocas, reporte los siguientes indicadores:\n","    - Pérdida de clasificación\n","    - Regularización\n","    - Accuracy del test\n","    - NMI y ARI\n","    - Promedio tamaño de clusters ± desviación estandar\n","3. Entrene t-SNE sobre los nodos en el *embedding* final y sobre los centroides, y grafique los resultados. Finalmente, comente sus resultados."]},{"cell_type":"markdown","metadata":{"id":"QrXhbabeXY7p"},"source":["Respuesta:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OYXvkMrhmf3F"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"VM-FfNWRmgrq"},"source":["## 3.3 MinCutPool (5 puntos)"]},{"cell_type":"markdown","metadata":{"id":"x8QhRxK6mjGT"},"source":["En esta sección se entrenará un modelo Graphormer utilizando el método de pooling jerárquico MinCut. Para ello, siga los siguientes pasos:\n","1. Entrene un Graphormer con pooling jerárquico `MinCutPool` con 300 épocas.\n","2. Por cada 20 épocas, reporte los siguientes indicadores:\n","    - Pérdida de clasificación\n","    - Regularización\n","    - Accuracy del test\n","    - NMI y ARI\n","    - Promedio tamaño de clusters ± desviación estandar\n","3. Entrene t-SNE sobre los nodos en el *embedding* final y sobre los centroides, y grafique los resultados. Finalmente, comente sus resultados."]},{"cell_type":"markdown","metadata":{"id":"9xvxNSZSmlBs"},"source":["Respuesta:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9re1BG_wmlt3"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"23xayHpJYcVp"},"source":["## 3.4 Conclusiones: DiffPool vs MinCutPool (5 puntos)"]},{"cell_type":"markdown","metadata":{"id":"71mdRHdFgQFC"},"source":["* ¿Qué modelo obtuvo mejor accuracy, NMI o ARI?\n","\n","* ¿Qué diferencias se observaron en la convergencia de las pérdidas entre DiffPool y MinCutPool?\n","\n","* ¿Hubo una diferencia clara en la capacidad de los modelos para formar clusters coherentes?\n","\n","* ¿Cuál método mostró una mejor separación de clases en los gráficos t-SNE?\n","\n","* ¿Cuál de los métodos recomendarías para este tipo de tarea y por qué?"]},{"cell_type":"markdown","metadata":{"id":"dsZxEwDbgQSC"},"source":["Respuesta:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r6b_hsVrgQ-T"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"dgl-arm","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
