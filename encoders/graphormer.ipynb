{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "985a9673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b937afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_metrics(G):\n",
    "    mean_degree = (2 * G.number_of_edges()) / G.number_of_nodes()\n",
    "\n",
    "    largest_component = max(nx.connected_components(G), key=len)\n",
    "    subgraph = G.subgraph(largest_component)\n",
    "\n",
    "    largest_component = max(nx.connected_components(G), key=len)\n",
    "    subgraph = G.subgraph(largest_component)\n",
    "    #diameter = nx.diameter(subgraph)\n",
    "    #avg_dist = nx.average_shortest_path_length(subgraph)\n",
    "    \n",
    "    print(f\"La red tiene {G.number_of_nodes()} nodos\")\n",
    "    print(f\"La red tiene {nx.number_connected_components(G)} componentes\")\n",
    "    print(f\"La red tiene {G.number_of_edges()} aristas\")\n",
    "    print(f\"El grado promedio de la red es {mean_degree}\")\n",
    "    #print(\"Diámetro de la red:\", diameter)\n",
    "    #print(\"Distancia promedio en la componente más grande:\", avg_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1bce44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juan_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random, numpy as np, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import TransformerConv, GlobalAttention\n",
    "from torch_geometric.utils import to_dense_adj, degree\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import eigsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596f38da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a39c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_pe(edge_index, num_nodes, k: int, device):\n",
    "    # Construye A dispersa simétrica\n",
    "    row = edge_index[0].cpu().numpy()\n",
    "    col = edge_index[1].cpu().numpy()\n",
    "    data = np.ones(len(row), dtype=np.float32)\n",
    "    A = sp.coo_matrix((data, (row, col)), shape=(num_nodes, num_nodes)).tocsr()\n",
    "\n",
    "    # Laplaciano normalizado: L = I - D^{-1/2} A D^{-1/2}\n",
    "    deg = np.asarray(A.sum(axis=1)).ravel()\n",
    "    deg[deg == 0] = 1.0\n",
    "    D_inv_sqrt = sp.diags(1.0 / np.sqrt(deg))\n",
    "    L = sp.eye(num_nodes, format=\"csr\") - D_inv_sqrt @ A @ D_inv_sqrt\n",
    "\n",
    "    # Autovectores más pequeños (k << N)\n",
    "    k = min(k, num_nodes)  # por si acaso\n",
    "    vals, vecs = eigsh(L, k=k, which='SM')  # 'SM' = smallest magnitude\n",
    "    U = torch.from_numpy(vecs).float().to(device)  # (N, k)\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8918d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_feature(edge_index, num_nodes, device):\n",
    "    deg = degree(edge_index[0], num_nodes=num_nodes)  # cuenta bien en no-dirigido\n",
    "    return torch.log1p(deg).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70656216",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphormerLiteEncoder(nn.Module):\n",
    "    \"\"\"Stack de TransformerConv con LapPE y degree encodings concatenados.\"\"\"\n",
    "    def __init__(self, in_ch, d_model=128, n_heads=4, n_layers=3, pe_dim=16, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.lin_in = nn.Linear(in_ch + pe_dim + 1, d_model)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerConv(d_model, d_model // n_heads, heads=n_heads, dropout=dropout, beta=True)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(d_model) for _ in range(n_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, edge_index, pe, deg_feat):\n",
    "        # x: (N, F) ; pe: (N, pe_dim); deg_feat: (N,1)\n",
    "        h = torch.cat([x, pe, deg_feat], dim=-1)\n",
    "        h = self.lin_in(h)\n",
    "        for conv, ln in zip(self.layers, self.norms):\n",
    "            h_res = h\n",
    "            h = conv(h, edge_index)\n",
    "            h = F.relu(h)\n",
    "            h = self.dropout(h)\n",
    "            h = ln(h + h_res)\n",
    "        return h  # (N, d_model)\n",
    "\n",
    "    class GraphReadoutGA(nn.Module):\n",
    "        def __init__(self, d_model, out_dim):\n",
    "            super().__init__()\n",
    "            self.gate = nn.Sequential(nn.Linear(d_model, 1))\n",
    "            self.pool = GlobalAttention(self.gate)\n",
    "            self.proj = nn.Linear(d_model, out_dim)\n",
    "\n",
    "        def forward(self, H):\n",
    "            batch = torch.zeros(H.size(0), dtype=torch.long, device=H.device)\n",
    "            g = self.pool(H, batch)          # (1, d_model)\n",
    "            return self.proj(g).squeeze(0)   # (out_dim,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    seed: int = 42\n",
    "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    d_model: int = 128\n",
    "    n_heads: int = 4\n",
    "    n_layers: int = 3\n",
    "    pe_dim: int = 16\n",
    "    dropout: float = 0.1\n",
    "    g_out: int = 256   # ← tamaño del embedding de grafo\n",
    "\n",
    "set_seed(42)\n",
    "cfg = Config()\n",
    "device = torch.device(cfg.device)\n",
    "\n",
    "# ====== CARGA TU GRAFO .GEXF Y CONSTRUYE PyG Data ======\n",
    "# Ruta a tu archivo\n",
    "gexf_path = \"grafo_santiago_filtrado_con_embeddings.gexf\"\n",
    "\n",
    "# Lee con NetworkX\n",
    "Gx = nx.read_gexf(gexf_path)\n",
    "\n",
    "# Si es dirigido, conviértelo a no dirigido para que degree/PE sean consistentes\n",
    "if isinstance(Gx, nx.DiGraph):\n",
    "    Gx = nx.Graph(Gx)  # o Gx.to_undirected()\n",
    "\n",
    "# Define un orden estable de nodos y un mapeo a índices [0..N-1]\n",
    "nodes = list(Gx.nodes())\n",
    "nid = {n: i for i, n in enumerate(nodes)}\n",
    "N = len(nodes)\n",
    "\n",
    "# --- Parseo de features por nodo ---\n",
    "def parse_feature(attrs, n=64):\n",
    "    keys = [f\"A{i:02d}\" for i in range(n)]\n",
    "    return np.array([float(attrs[k]) for k in keys], dtype=np.float32)\n",
    "    \n",
    "X = np.stack([parse_feature(Gx.nodes[n]) for n in nodes], axis=0)  # (N, d)\n",
    "d = X.shape[1]\n",
    "\n",
    "# --- edge_index ---\n",
    "edges = [(nid[u], nid[v]) for (u, v) in Gx.edges()]\n",
    "# Asegura simetría (por si hay alguna arista suelta en un solo sentido)\n",
    "edges = edges + [(j, i) for (i, j) in edges if (j, i) not in edges]\n",
    "\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()  # (2, E)\n",
    "\n",
    "# Construye Data y manda a device\n",
    "data = Data(x=torch.tensor(X, dtype=torch.float32),\n",
    "            edge_index=edge_index)\n",
    "data = data.to(cfg.device)\n",
    "\n",
    "# (Opcional) por si deseas guardar el id original de cada índice\n",
    "# data.nid_map = nodes  # lista con el nombre original de cada nodo en la posición i\n",
    "\n",
    "# ---- Preparación ----\n",
    "pe = laplacian_pe(data.edge_index, data.num_nodes, cfg.pe_dim, device)   # (N, pe_dim)\n",
    "deg_feat = degree_feature(data.edge_index, data.num_nodes, device)       # (N, 1)\n",
    "\n",
    "encoder = GraphormerLiteEncoder(\n",
    "    in_ch=data.x.size(1),\n",
    "    d_model=cfg.d_model,\n",
    "    n_heads=cfg.n_heads,\n",
    "    n_layers=cfg.n_layers,\n",
    "    pe_dim=cfg.pe_dim,\n",
    "    dropout=cfg.dropout\n",
    ").to(device)\n",
    "\n",
    "readout = GraphReadoutGA(d_model=cfg.d_model, out_dim=cfg.g_out).to(device)\n",
    "\n",
    "# ---- Solo codificar (sin entrenamiento) ----\n",
    "encoder.eval(); readout.eval()\n",
    "with torch.no_grad():\n",
    "    H = encoder(data.x, data.edge_index, pe, deg_feat)   # (N, d_model)\n",
    "    g_emb = readout(H)                                   # (g_out,)\n",
    "\n",
    "torch.save(g_emb.cpu(), \"graph_embedding.pt\")\n",
    "print(\"Embedding del grafo:\", tuple(g_emb.shape), \"guardado en graph_embedding.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
